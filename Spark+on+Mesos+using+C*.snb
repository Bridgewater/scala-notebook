{
  "metadata":{
    "name":"Spark on Mesos using C*",
    "user_save_timestamp":"2014-11-03T16:31:28.355Z",
    "auto_save_timestamp":"2014-11-03T16:34:31.727Z"
  },
  "worksheets":[{
    "cells":[{
      "cell_type":"markdown",
      "source":"### Spark config"
    },{
      "cell_type":"code",
      "input":"updateRepo(\"/tmp/repo\")\nresolveAndAddToJars(\"com.datastax.spark\", \"spark-cassandra-connector_2.10\", \"1.1.0-beta1\", true)",
      "language":"scala",
      "collapsed":false,
      "prompt_number":1,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":":cp\n/tmp/repo/org/scala-lang/scala-compiler/2.10.4/scala-compiler-2.10.4.jar\n/tmp/repo/com/codahale/metrics/metrics-core/3.0.2/metrics-core-3.0.2.jar\n/tmp/repo/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar\n/tmp/repo/com/datastax/spark/spark-cassandra-connector_2.10/1.1.0-beta1/spark-cassandra-connector_2.10-1.1.0-beta1.jar\n/tmp/repo/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar\n/tmp/repo/commons-codec/commons-codec/1.6/commons-codec-1.6.jar\n/tmp/repo/com/datastax/cassandra/cassandra-driver-core/2.1.0/cassandra-driver-core-2.1.0.jar\n/tmp/repo/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar\n/tmp/repo/com/google/guava/guava/16.0.1/guava-16.0.1.jar\n/tmp/repo/org/apache/cassandra/cassandra-clientutil/2.1.0/cassandra-clientutil-2.1.0.jar\n/tmp/repo/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar\n/tmp/repo/joda-time/joda-time/2.3/joda-time-2.3.jar\n/tmp/repo/org/apache/cassandra/cassandra-thrift/2.1.0/cassandra-thrift-2.1.0.jar\n/tmp/repo/com/datastax/cassandra/cassandra-driver-core/2.1.0/cassandra-driver-core-2.1.0-sources.jar\n/tmp/repo/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar\n/tmp/repo/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar\n/tmp/repo/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar\n/tmp/repo/io/netty/netty/3.9.0.Final/netty-3.9.0.Final.jar\n/tmp/repo/org/apache/thrift/libthrift/0.9.1/libthrift-0.9.1.jar\n/tmp/repo/org/joda/joda-convert/1.2/joda-convert-1.2.jar",
      "language":"scala",
      "collapsed":false,
      "prompt_number":2,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"reset(\"Notebook on dnode-3\", lastChanges = (c:SparkConf) => {\n  c.set(\"spark.executor.memory\", \"5G\")\n   .set(\"spark.executor.uri\", \"hdfs://nnode-0.hdfs.private:8020/artifacts/spark-1.1.0.tgz\")\n   .set(\"spark.cassandra.connection.host\", \"10.97.2.104\")\n   .set(\"spark.master\", \"mesos://zk://zookeeper-0.zookeeper.private:2181,zookeeper-1.zookeeper.private:2181,zookeeper-2.zookeeper.private:2181/mesos\")\n   .set(\"spark.driver.host\", \"dnode-3.hdfs.private\")\n   .set(\"spark.broadcast.factory\", \"org.apache.spark.broadcast.HttpBroadcastFactory\")\n   .set(\"spark.local.dir\", \"/mnt4/spark-local\")\n   //.set(\"spark.cleaner.ttl\", \"-1\")\n   .set(\"spark.storage.memoryFraction\", \"0.1\")\n   .set(\"spark.shuffle.memoryFraction\", \"0.4\")\n    \n})",
      "language":"scala",
      "collapsed":false,
      "prompt_number":3,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"sparkContext.getConf.toDebugString",
      "language":"scala",
      "collapsed":false,
      "prompt_number":25,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"import org.apache.spark.ui.notebook.front.widgets.SparkInfo\nimport scala.concurrent.duration._\nnew SparkInfo(sparkContext, checkInterval=1 second, execNumber=None)",
      "language":"scala",
      "collapsed":false,
      "prompt_number":26,
      "outputs":[]
    },{
      "cell_type":"markdown",
      "source":"#### Access cassandra"
    },{
      "cell_type":"code",
      "input":"import com.datastax.spark.connector._                                    \nimport org.apache.spark.sql.cassandra.CassandraSQLContext\n\nval cc = new CassandraSQLContext(sparkContext)\nval rdd: org.apache.spark.sql.SchemaRDD = cc.sql(\"SELECT * from tch.actualvalues\")",
      "language":"scala",
      "collapsed":false,
      "prompt_number":27,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"rdd.count",
      "language":"scala",
      "collapsed":false,
      "prompt_number":28,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"import cc._\n\nval proj = rdd.select( 'id, 'metrics )\n",
      "language":"scala",
      "collapsed":false,
      "prompt_number":29,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"import SparkContext._\nval l = proj.map(r => (r.getString(0), r(1).asInstanceOf[Map[String, Double]].get(\"mem\")))\n    .filter(_._2.isDefined)\n    .map(x => (x._1, x._2.get))\n    .reduceByKey(_ + _)\n    .take(100).toList\n<ul>{for ((x,y) <- l) yield <li>{x} → {y}</li>}</ul>  ",
      "language":"scala",
      "collapsed":false,
      "prompt_number":30,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"",
      "language":"scala",
      "collapsed":false,
      "prompt_number":9,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"",
      "language":"scala",
      "collapsed":true,
      "outputs":[]
    }]
  }],
  "autosaved":[{
    "cells":[{
      "cell_type":"markdown",
      "source":"### Spark config"
    },{
      "cell_type":"code",
      "input":"updateRepo(\"/tmp/repo\")\nresolveAndAddToJars(\"com.datastax.spark\", \"spark-cassandra-connector_2.10\", \"1.1.0-beta1\", true)",
      "language":"scala",
      "collapsed":false,
      "prompt_number":9,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":":cp\n/tmp/repo/org/scala-lang/scala-compiler/2.10.4/scala-compiler-2.10.4.jar\n/tmp/repo/com/codahale/metrics/metrics-core/3.0.2/metrics-core-3.0.2.jar\n/tmp/repo/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar\n/tmp/repo/com/datastax/spark/spark-cassandra-connector_2.10/1.1.0-beta1/spark-cassandra-connector_2.10-1.1.0-beta1.jar\n/tmp/repo/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar\n/tmp/repo/commons-codec/commons-codec/1.6/commons-codec-1.6.jar\n/tmp/repo/com/datastax/cassandra/cassandra-driver-core/2.1.0/cassandra-driver-core-2.1.0.jar\n/tmp/repo/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar\n/tmp/repo/com/google/guava/guava/16.0.1/guava-16.0.1.jar\n/tmp/repo/org/apache/cassandra/cassandra-clientutil/2.1.0/cassandra-clientutil-2.1.0.jar\n/tmp/repo/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar\n/tmp/repo/joda-time/joda-time/2.3/joda-time-2.3.jar\n/tmp/repo/org/apache/cassandra/cassandra-thrift/2.1.0/cassandra-thrift-2.1.0.jar\n/tmp/repo/com/datastax/cassandra/cassandra-driver-core/2.1.0/cassandra-driver-core-2.1.0-sources.jar\n/tmp/repo/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar\n/tmp/repo/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar\n/tmp/repo/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar\n/tmp/repo/io/netty/netty/3.9.0.Final/netty-3.9.0.Final.jar\n/tmp/repo/org/apache/thrift/libthrift/0.9.1/libthrift-0.9.1.jar\n/tmp/repo/org/joda/joda-convert/1.2/joda-convert-1.2.jar",
      "language":"scala",
      "collapsed":false,
      "prompt_number":10,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"reset(\"Notebook on dnode-3\", lastChanges = (c:SparkConf) => {\n  c.set(\"spark.executor.memory\", \"5G\")\n   .set(\"spark.executor.uri\", \"hdfs://nnode-0.hdfs.private:8020/artifacts/spark-1.1.0.tgz\")\n   .set(\"spark.cassandra.connection.host\", \"10.97.2.104\")\n   .set(\"spark.master\", \"mesos://zk://zookeeper-0.zookeeper.private:2181,zookeeper-1.zookeeper.private:2181,zookeeper-2.zookeeper.private:2181/mesos\")\n   .set(\"spark.driver.host\", \"dnode-3.hdfs.private\")\n   .set(\"spark.broadcast.factory\", \"org.apache.spark.broadcast.HttpBroadcastFactory\")\n   .set(\"spark.local.dir\", \"/mnt4/spark-local\")\n   //.set(\"spark.cleaner.ttl\", \"-1\")\n   .set(\"spark.storage.memoryFraction\", \"0.1\")\n   .set(\"spark.shuffle.memoryFraction\", \"0.4\")\n    \n})",
      "language":"scala",
      "collapsed":false,
      "prompt_number":11,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"sparkContext.getConf.toDebugString",
      "language":"scala",
      "collapsed":false,
      "prompt_number":12,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"import org.apache.spark.ui.notebook.front.widgets.SparkInfo\nimport scala.concurrent.duration._\nnew SparkInfo(sparkContext, checkInterval=1 second, execNumber=None)",
      "language":"scala",
      "collapsed":false,
      "prompt_number":13,
      "outputs":[]
    },{
      "cell_type":"markdown",
      "source":"#### Access cassandra"
    },{
      "cell_type":"code",
      "input":"import com.datastax.spark.connector._                                    \nimport org.apache.spark.sql.cassandra.CassandraSQLContext\n\nval cc = new CassandraSQLContext(sparkContext)\nval rdd: org.apache.spark.sql.SchemaRDD = cc.sql(\"SELECT * from tch.actualvalues\")",
      "language":"scala",
      "collapsed":false,
      "prompt_number":14,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"rdd.count",
      "language":"scala",
      "collapsed":false,
      "prompt_number":15,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"import cc._\n\nval proj = rdd.select( 'id, 'metrics )\n",
      "language":"scala",
      "collapsed":false,
      "prompt_number":16,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"import SparkContext._\nval l = proj.map(r => (r.getString(0), r(1).asInstanceOf[Map[String, Double]].get(\"mem\")))\n    .filter(_._2.isDefined)\n    .map(x => (x._1, x._2.get))\n    .reduceByKey(_ + _)\n    .take(100).toList\n<ul>{for ((x,y) <- l) yield <li>{x} → {y}</li>}</ul>  ",
      "language":"scala",
      "collapsed":false,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"",
      "language":"scala",
      "collapsed":false,
      "prompt_number":9,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":":sql select * from test where name = {String: name} and first = {String: first}",
      "language":"scala",
      "collapsed":true,
      "outputs":[]
    },{
      "cell_type":"code",
      "input":"",
      "language":"scala",
      "collapsed":true,
      "outputs":[]
    }]
  }],
  "nbformat":3
}